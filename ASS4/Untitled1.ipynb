{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "927c0fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import tensorflow as tf\n",
    "# from tensorflow.keras import layers, models\n",
    "# import matplotlib.pyplot as plt\n",
    "# import pandas as pd\n",
    "\n",
    "# # Function to generate noisy gravitational wave-like data\n",
    "# def generate_gw_data(n_samples, noise_level=0.1):\n",
    "#     time = np.linspace(0, 1, n_samples)\n",
    "#     signal = np.sin(2 * np.pi * time * 5)  # Simulated GW signal (sine wave)\n",
    "#     noise = noise_level * np.random.randn(n_samples)  # Adding Gaussian noise\n",
    "#     data = signal + noise\n",
    "#     return data, signal\n",
    "\n",
    "# # Set the number of samples\n",
    "# n_samples = 100\n",
    "\n",
    "# # Prepare the data\n",
    "# x_data, y_data = generate_gw_data(n_samples)\n",
    "# x_data = x_data.reshape(-1, 1)  # Reshape for input shape (n_samples, 1)\n",
    "# y_data = y_data.reshape(-1, 1)  # Reshape to ensure it's (n_samples, 1)\n",
    "\n",
    "# # Build and compile the model\n",
    "# model = models.Sequential([\n",
    "#     layers.Dense(5, activation='relu', input_shape=(1,)),  # First hidden layer\n",
    "#     layers.Dense(5, activation='relu'),                    # Second hidden layer\n",
    "#     layers.Dense(1)                                        # Output layer\n",
    "# ])\n",
    "\n",
    "# optimizer_01 = tf.keras.optimizers.SGD(learning_rate=0.01)\n",
    "# model.compile(optimizer=optimizer_01, loss='mean_squared_error')\n",
    "\n",
    "# # Function to extract model info for 10 steps\n",
    "# def extract_model_info(model, x_data, y_data, optimizer):\n",
    "#     info = {\"step\": [], \"weights\": [], \"gradients\": [], \"outputs\": [], \"loss\": []}\n",
    "\n",
    "#     for step in range(10):  # Run 10 steps of optimization\n",
    "#         with tf.GradientTape() as tape:\n",
    "#             predictions = model(x_data)\n",
    "#             # Explicitly calculate the loss using mean_squared_error\n",
    "#             loss_value = tf.keras.losses.mean_squared_error(y_data, predictions)\n",
    "#             loss_value = tf.reduce_mean(loss_value)  # Reduce to scalar\n",
    "\n",
    "#         # Compute gradients and get weights\n",
    "#         gradients = tape.gradient(loss_value, model.trainable_variables)\n",
    "#         weights = model.trainable_variables\n",
    "\n",
    "#         # Apply gradients (this updates the weights)\n",
    "#         optimizer.apply_gradients(zip(gradients, weights))\n",
    "\n",
    "#         # Store step information\n",
    "#         info[\"step\"].append(step + 1)\n",
    "#         info[\"weights\"].append([w.numpy().tolist() for w in weights])  # Extracting list of floats\n",
    "#         info[\"gradients\"].append([g.numpy().tolist() for g in gradients])  # Extracting list of floats\n",
    "#         info[\"outputs\"].append(predictions.numpy().flatten().tolist())  # Extract output as list\n",
    "#         info[\"loss\"].append(float(loss_value.numpy()))  # Single float\n",
    "\n",
    "#     return info\n",
    "\n",
    "# # Create optimizer for learning rate = 0.2\n",
    "# optimizer_02 = tf.keras.optimizers.SGD(learning_rate=0.2)\n",
    "\n",
    "# # Extract information for both learning rates\n",
    "# info_lr_01 = extract_model_info(model, x_data, y_data, optimizer_01)\n",
    "# info_lr_02 = extract_model_info(model, x_data, y_data, optimizer_02)\n",
    "\n",
    "# # Create tables for both learning rates\n",
    "# def create_table(info):\n",
    "#     table = pd.DataFrame({\n",
    "#         'Step': info[\"step\"],\n",
    "#         'Loss': info[\"loss\"],\n",
    "#         'Weights (Layer 1)': [np.mean(w[0]) for w in info[\"weights\"]],  # Simplified to mean of the layer's weights\n",
    "#         'Gradients (Layer 1)': [np.mean(g[0]) for g in info[\"gradients\"]],  # Mean gradient\n",
    "#         'Outputs (Mean)': [np.mean(o) for o in info[\"outputs\"]]  # Mean of predictions\n",
    "#     })\n",
    "#     return table\n",
    "\n",
    "# table_lr_01 = create_table(info_lr_01)\n",
    "# table_lr_02 = create_table(info_lr_02)\n",
    "\n",
    "# # Save the tables to CSV files\n",
    "# table_lr_01.to_csv('table_lr_01.csv', index=False)\n",
    "# table_lr_02.to_csv('table_lr_02.csv', index=False)\n",
    "\n",
    "# print(\"Tables saved successfully!\")\n",
    "# print(table_lr_01.head())\n",
    "# print(table_lr_02.head())\n",
    "\n",
    "# # Visualization (optional)\n",
    "# # This will plot the training loss for both learning rates\n",
    "# plt.plot(table_lr_01['Step'], table_lr_01['Loss'], label='Learning Rate 0.01')\n",
    "# plt.plot(table_lr_02['Step'], table_lr_02['Loss'], label='Learning Rate 0.2')\n",
    "# plt.xlabel('Step')\n",
    "# plt.ylabel('Loss')\n",
    "# plt.legend()\n",
    "# plt.title('Loss over 10 Steps')\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a8fb89f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pydot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "918b5099",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b8b276e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot network structure (use a placeholder diagram for illustrative purposes)\n",
    "from tensorflow.keras.utils import plot_model\n",
    "plot_model(model, to_file=\"network_structure.png\", show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "28122973",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tables saved successfully!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-24 21:30:29.419684: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "# Generate noisy gravitational wave-like data\n",
    "def generate_gw_data(n_samples, noise_level=0.1):\n",
    "    time = np.linspace(0, 1, n_samples)\n",
    "    signal = np.sin(2 * np.pi * time * 5)  # Simulated GW signal (sine wave)\n",
    "    noise = noise_level * np.random.randn(n_samples)  # Gaussian noise\n",
    "    data = signal + noise\n",
    "    return data, signal\n",
    "\n",
    "# Prepare data\n",
    "n_samples = 100\n",
    "x_data, y_data = generate_gw_data(n_samples)\n",
    "x_data = x_data.reshape(-1, 1)\n",
    "y_data = y_data.reshape(-1, 1)\n",
    "\n",
    "# Build and compile the model\n",
    "model = models.Sequential([\n",
    "    layers.Dense(5, activation='relu', input_shape=(1,)),  # First hidden layer\n",
    "    layers.Dense(5, activation='relu'),                    # Second hidden layer\n",
    "    layers.Dense(1)                                        # Output layer\n",
    "])\n",
    "\n",
    "def extract_model_info(model, x_data, y_data, optimizer):\n",
    "    info = {\"step\": [], \"weights\": [], \"gradients\": [], \"outputs\": [], \"loss\": []}\n",
    "\n",
    "    for step in range(10):  # 10 steps of optimization\n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions = model(x_data)\n",
    "            loss_value = tf.keras.losses.mean_squared_error(y_data, predictions)\n",
    "            loss_value = tf.reduce_mean(loss_value)\n",
    "\n",
    "        # Compute gradients and get weights\n",
    "        gradients = tape.gradient(loss_value, model.trainable_variables)\n",
    "        weights = model.trainable_variables\n",
    "\n",
    "        # Apply gradients (this updates the weights)\n",
    "        optimizer.apply_gradients(zip(gradients, weights))\n",
    "\n",
    "        # Store step information\n",
    "        info[\"step\"].append(step + 1)\n",
    "        info[\"weights\"].append([w.numpy() for w in weights])\n",
    "        info[\"gradients\"].append([g.numpy() for g in gradients])\n",
    "        info[\"outputs\"].append(predictions.numpy())\n",
    "        info[\"loss\"].append(loss_value.numpy())\n",
    "\n",
    "    return info\n",
    "\n",
    "# Optimizers for different learning rates\n",
    "optimizer_01 = tf.keras.optimizers.SGD(learning_rate=0.1)\n",
    "optimizer_05 = tf.keras.optimizers.SGD(learning_rate=0.5)\n",
    "\n",
    "# Extract info for both learning rates\n",
    "info_lr_01 = extract_model_info(model, x_data, y_data, optimizer_01)\n",
    "info_lr_05 = extract_model_info(model, x_data, y_data, optimizer_05)\n",
    "\n",
    "# Create tables for weights, gradients, outputs, and loss\n",
    "def create_table(info):\n",
    "    table = pd.DataFrame({\n",
    "        'Step': info[\"step\"],\n",
    "        'Loss': info[\"loss\"],\n",
    "        'Weights (Layer 1)': [str(w[0]) for w in info[\"weights\"]],\n",
    "        'Gradients (Layer 1)': [str(g[0]) for g in info[\"gradients\"]],\n",
    "        'Outputs': [str(o) for o in info[\"outputs\"]]\n",
    "    })\n",
    "    return table\n",
    "\n",
    "# Create and save tables\n",
    "table_lr_01 = create_table(info_lr_01)\n",
    "table_lr_05 = create_table(info_lr_05)\n",
    "\n",
    "# Save to CSV\n",
    "table_lr_01.to_csv('table_lr_01.csv', index=False)\n",
    "table_lr_05.to_csv('table_lr_05.csv', index=False)\n",
    "\n",
    "print(\"Tables saved successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e57ad6fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in /opt/anaconda3/lib/python3.8/site-packages (2.6.0)\n",
      "Requirement already satisfied: numpy~=1.19.2 in /opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (1.19.5)\n",
      "Requirement already satisfied: absl-py~=0.10 in /opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (0.15.0)\n",
      "Requirement already satisfied: astunparse~=1.6.3 in /opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers~=1.12.0 in /opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (1.12)\n",
      "Requirement already satisfied: google-pasta~=0.2 in /opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py~=3.1.0 in /opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (3.1.0)\n",
      "Requirement already satisfied: keras-preprocessing~=1.1.2 in /opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied: opt-einsum~=3.3.0 in /opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in /opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (3.16.0)\n",
      "Requirement already satisfied: six~=1.15.0 in /opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (1.15.0)\n",
      "Requirement already satisfied: termcolor~=1.1.0 in /opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: typing-extensions~=3.7.4 in /opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (3.7.4.3)\n",
      "Requirement already satisfied: wheel~=0.35 in /opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (0.43.0)\n",
      "Requirement already satisfied: wrapt~=1.12.1 in /opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (1.12.1)\n",
      "Requirement already satisfied: gast==0.4.0 in /opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (0.4.0)\n",
      "Requirement already satisfied: tensorboard~=2.6 in /opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (2.11.2)\n",
      "Requirement already satisfied: tensorflow-estimator~=2.6 in /opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (2.6.0)\n",
      "Requirement already satisfied: keras~=2.6 in /opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (2.6.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.39 in /opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (1.39.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /opt/anaconda3/lib/python3.8/site-packages (from tensorboard~=2.6->tensorflow) (2.35.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /opt/anaconda3/lib/python3.8/site-packages (from tensorboard~=2.6->tensorflow) (0.4.6)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/anaconda3/lib/python3.8/site-packages (from tensorboard~=2.6->tensorflow) (3.6)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/anaconda3/lib/python3.8/site-packages (from tensorboard~=2.6->tensorflow) (2.31.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /opt/anaconda3/lib/python3.8/site-packages (from tensorboard~=2.6->tensorflow) (69.5.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /opt/anaconda3/lib/python3.8/site-packages (from tensorboard~=2.6->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /opt/anaconda3/lib/python3.8/site-packages (from tensorboard~=2.6->tensorflow) (1.8.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /opt/anaconda3/lib/python3.8/site-packages (from tensorboard~=2.6->tensorflow) (3.0.3)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/anaconda3/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (5.5.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/anaconda3/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (0.4.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/anaconda3/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/anaconda3/lib/python3.8/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow) (2.0.0)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /opt/anaconda3/lib/python3.8/site-packages (from markdown>=2.6.8->tensorboard~=2.6->tensorflow) (5.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (2024.8.30)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/anaconda3/lib/python3.8/site-packages (from werkzeug>=1.0.1->tensorboard~=2.6->tensorflow) (2.1.5)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/anaconda3/lib/python3.8/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard~=2.6->tensorflow) (3.17.0)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /opt/anaconda3/lib/python3.8/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/anaconda3/lib/python3.8/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow) (3.2.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "612e6b1d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
